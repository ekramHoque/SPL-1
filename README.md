# PicoDB - Lightweight File-Based Database

**PicoDB** is a compact, educational database management system implemented in C++17 that stores data in binary files with efficient indexing mechanisms. It supports SQL-like commands for table creation, data insertion, retrieval, and display.

---

## ğŸš€ Features

- **SQL-like Command Interface**: CREATE, INSERT, SELECT, SHOW commands
- **Multiple Indexing Methods**: Hash-based indexing and B+ Tree (planned)
- **Compression**: Varint encoding for efficient integer storage
- **Binary Storage**: Compact binary file format for data persistence
- **Type Support**: INT, TEXT, FLOAT, BOOL data types
- **Primary Key Constraints**: Enforce unique primary keys
- **WHERE Clause**: Query data with equality and BETWEEN conditions

---

## ğŸ“ Project Structure

```
picodb/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.cpp              # Entry point
â”‚   â”œâ”€â”€ commands/             # Command execution logic
â”‚   â”‚   â”œâ”€â”€ create.cpp/h      # CREATE TABLE handler
â”‚   â”‚   â”œâ”€â”€ insert.cpp/h      # INSERT handler
â”‚   â”‚   â”œâ”€â”€ select.cpp/h      # SELECT handler
â”‚   â”‚   â”œâ”€â”€ show.cpp/h        # SHOW TABLE handler
â”‚   â”‚   â””â”€â”€ utils.cpp/h       # Utility functions
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â””â”€â”€ parser.cpp/h      # SQL command parser
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ file_manager.cpp/h   # File I/O operations
â”‚   â”‚   â”œâ”€â”€ varint.cpp/h         # Varint compression
â”‚   â”‚   â””â”€â”€ bitfield.cpp/h       # Bitfield utilities
â”‚   â””â”€â”€ index/
â”‚       â”œâ”€â”€ hash_index.cpp/h     # Hash table indexing
â”‚       â””â”€â”€ bplusTree_index.cpp/h # B+ tree (future)
â”œâ”€â”€ data/                     # Database files (auto-created)
â”‚   â””â”€â”€ [table_name]/
â”‚       â”œâ”€â”€ [table_name].meta    # Table schema
â”‚       â”œâ”€â”€ [table_name].data    # Binary data records
â”‚       â””â”€â”€ [table_name].hashidx # Hash index file
â””â”€â”€ docs/
    â”œâ”€â”€ readme_Compres.md     # Compression details
    â””â”€â”€ readme_Hashing.md     # Hash indexing details
```

---

## ğŸ› ï¸ Building and Running

### Prerequisites
- C++17 compatible compiler (g++ 7+, clang 5+)
- Linux/Unix environment

### Compilation
```bash
cd PicoDB
g++ -std=c++17 -O2 \
  -I./src -I./src/storage -I./src/commands -I./src/parser -I./src/index \
  -o picodb \
  src/main.cpp src/commands/*.cpp src/parser/*.cpp src/storage/*.cpp src/index/*.cpp
```

### Run
```bash
./picodb
```

---

## ğŸ“– Usage Examples

### 1. Start PicoDB
```
=============================================
              PicoDB - File Database         
=============================================
Choose indexing method:
  1. Hashing 
  2. B+ Tree 
Enter option (1 or 2): 1
[INFO] Hashing index selected.
PicoDB> 
```

### 2. Create a Table
```sql
PicoDB> CREATE TABLE student(id INT PRIMARY, name TEXT, dept TEXT, gpa FLOAT);
[OK] Table student created sucessFully
[INFO] : Primary Key -> id
```

### 3. Insert Records
```sql
PicoDB> INSERT INTO student VALUES(1, "Ekram", "IIT", 3.7);
Insertes succesfully at offset 0

PicoDB> INSERT INTO student VALUES(2, "Opu", "EEE", 3.5);
Insertes succesfully at offset 28

PicoDB> INSERT INTO student VALUES(3, "Rafin", "CSE", 3.9);
Insertes succesfully at offset 56
```

### 4. Display All Records
```sql
PicoDB> SHOW TABLE student;
-------------------------------------------------
| id | name | dept | gpa 
-------------------------------------------------
| 1 | Ekram | IIT | 3.7 
| 2 | Opu | EEE | 3.5 
| 3 | Rafin | CSE | 3.9 
-------------------------------------------------
```

### 5. Query with WHERE Clause
```sql
PicoDB> SELECT * FROM student WHERE name = "Ekram";
[INFO] Search for name
-------------------------------------------------
| id | name | dept | gpa 
-------------------------------------------------
| 1 | Ekram | IIT | 3.7

PicoDB> SELECT * FROM student WHERE id = 2;
[INFO] Search for id
-------------------------------------------------
| id | name | dept | gpa 
-------------------------------------------------
| 2 | Opu | EEE | 3.5 
```

### 6. Exit
```sql
PicoDB> exit
Exiting PicoDB. Goodbye!
```

---

## ğŸ—ï¸ System Architecture

### High-Level Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     User     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ SQL Command
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parser Module   â”‚  â—„â”€â”€ Regex-based SQL parsing
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ParsedCommand struct
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Command Executor â”‚  â—„â”€â”€ Route to appropriate handler
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼             â–¼             â–¼              â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ CREATE â”‚   â”‚ INSERT â”‚   â”‚ SELECT â”‚    â”‚  SHOW  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚            â”‚            â”‚             â”‚
        â–¼            â–¼            â–¼             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚          File Manager (Storage Layer)        â”‚
   â”‚  â€¢ writeMeta()  â€¢ readMeta()                 â”‚
   â”‚  â€¢ appendRecord()  â€¢ readRecord()            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                   â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Index  â”‚         â”‚   Data   â”‚
   â”‚  Files  â”‚         â”‚   Files  â”‚
   â”‚ (.hashidx)â”‚       â”‚  (.data) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Storage Format Details

#### 1. **Metadata File (`.meta`)**
Stores table schema in plain text:
```
COLUMN: 3
id INTPRIMARY
name TEXT
dept TEXT
```

#### 2. **Data File (`.data`)**
Binary format with Varint-encoded record lengths:
```
[Varint: RecordLength] [Record Data]
[Varint: RecordLength] [Record Data]
...
```

**Record Structure:**
```
[TypeFlag: 1 byte] [Value Data]
[TypeFlag: 1 byte] [Value Data]
...
```

Type Flags:
- `'I'` = Integer (Varint-encoded)
- `'S'` = String (Varint length + raw bytes)
- `'F'` = Float (4 bytes, IEEE 754)
- `'B'` = Boolean (1 byte: 0 or 1)

#### 3. **Hash Index File (`.hashidx`)**
Binary format mapping column values to file offsets:
```
[ColumnName\0] [Value\0] [OffsetCount: 8 bytes] [Offset1: 8 bytes] [Offset2: 8 bytes] ...
```

---

## ğŸ”„ Detailed Flow Diagrams

### INSERT Operation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INSERT INTO student VALUES(1, "Ekram", "IIT")          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Parse Command  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Read .meta     â”‚ â—„â”€â”€â”€ Load schema
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Load Hash Index â”‚ â—„â”€â”€â”€ Load existing index from disk
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Check Primary   â”‚ â—„â”€â”€â”€ Verify uniqueness
            â”‚ Key Constraint  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Encode Record:  â”‚
            â”‚  'I' + varint(1)â”‚ â—„â”€â”€â”€ Compress data
            â”‚  'S' + len +    â”‚
            â”‚      "Ekram"    â”‚
            â”‚  'S' + len +    â”‚
            â”‚      "IIT"      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Append to .data â”‚ â—„â”€â”€â”€ Returns offset (e.g., 0)
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Update Index:   â”‚
            â”‚  id -> 1 -> [0] â”‚ â—„â”€â”€â”€ Map each column/value to offset
            â”‚  name -> Ekram  â”‚
            â”‚         -> [0]  â”‚
            â”‚  dept -> IIT    â”‚
            â”‚         -> [0]  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Save Index to   â”‚ â—„â”€â”€â”€ Persist index to disk
            â”‚   .hashidx      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜Ekram
```

### SELECT Operation Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SELECT * FROM student WHERE name = "Ekram"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Parse Command  â”‚
            â”‚  Extract:       â”‚
            â”‚   - table: student
            â”‚   - column: name â”‚
            â”‚   - value: Ekram â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Read .meta     â”‚ â—„â”€â”€â”€ Load schema
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Load Hash Index â”‚ â—„â”€â”€â”€ Load index into memory
            â”‚   from .hashidx â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Hash Lookup:  â”‚
            â”‚ idx["name"]     â”‚ â—„â”€â”€â”€ O(1) average lookup
            â”‚    ["Ekram"]    â”‚
            â”‚    â†’ [0]        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Read Record at  â”‚
            â”‚   offset 0      â”‚ â—„â”€â”€â”€ Seek to position in .data
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Decode Record:  â”‚
            â”‚  Parse varint   â”‚ â—„â”€â”€â”€ Decompress data
            â”‚  Extract fields â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Display Result  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Key Design Decisions

### 1. **Varint Compression**
- Small integers use fewer bytes (e.g., `1` = 1 byte instead of 8)
- Details: See [docs/readme_Compres.md](docs/readme_Compres.md)

### 2. **Hash Index Structure**
- Multi-level map: `Column â†’ Value â†’ [Offsets]`
- Supports multiple records with same value
- Details: See [docs/readme_Hashing.md](docs/readme_Hashing.md)

### 3. **Binary Storage**
- Type flags distinguish data types at runtime
- Self-describing format for schema evolution

### 4. **Parser Design**
- Regex-based for simplicity
- Handles quotes, semicolons, whitespace variations

---

## ğŸ“Š Performance Characteristics

| Operation | Time Complexity | Space Complexity |
|-----------|----------------|------------------|
| INSERT    | O(1) average   | O(n) index size  |
| SELECT (indexed) | O(1) average | O(1) per result |
| SHOW      | O(n)           | O(1)             |
| CREATE    | O(1)           | O(m) metadata    |

*where n = number of records, m = number of columns*

---

## ğŸ§ª Testing Example

```bash
# Clean start
rm -rf data/

# Run PicoDB
./picodb

# Test session:
1  # Select hashing
CREATE TABLE employee(id INT PRIMARY, name TEXT, salary FLOAT);
INSERT INTO employee VALUES(101, "Roni", 50000.5);
INSERT INTO employee VALUES(102, "Rahi", 60000.0);
SHOW TABLE employee;
SELECT * FROM employee WHERE id = 101;
exit
```

---

## ğŸ” File Format Examples

### After creating and inserting data:

**data/student/student.meta:**
```
COLUMN: 3
id INTPRIMARY
name TEXT
dept TEXT
```

**data/student/student.data (hexdump):**
```
00000000: 09 49 01 53 05 41 6c 69 63 65 53 03 43 53 45  .I.S.Ekram.S.IIT
          ^  ^  ^  ^  ^  ^^^^^^^^^^^  ^  ^  ^^^^^^^  
          â”‚  â”‚  â”‚  â”‚  â”‚      â””â”€ "Ekram"
          â”‚  â”‚  â”‚  â”‚  â””â”€ Length: 5
          â”‚  â”‚  â”‚  â””â”€ Type: String
          â”‚  â”‚  â””â”€ Varint: 1
          â”‚  â””â”€ Type: Integer  
          â””â”€ Record length: 9 bytes
```

**data/student/student.hashidx (structure):**
```
id\0 1\0 [count=1] [offset=0]
name\0 Ekram\0 [count=1] [offset=0]
dept\0 IIT\0 [count=1] [offset=0]
```

---

## ğŸš§ Limitations & Future Work

### Current Limitations
- No UPDATE or DELETE commands
- No JOIN operations
- Single-user, file-locking not implemented
- Limited WHERE operators (only `=` supported)
- No BETWEEN implementation yet(later)

### Planned Features
- [ ] B+ Tree indexing for range queries
- [ ] UPDATE and DELETE operations
- [ ] Transaction support
- [ ] Multi-table queries (JOIN)
- [ ] Query optimization
- [ ] Crash recovery

---

## ğŸ“š Additional Documentation

- **[Compression Details](docs/readme_Compres.md)**: Varint encoding algorithm
- **[Hash Indexing](docs/readme_Hashing.md)**: Hash table implementation
- **[B+ Tree](docs/readme_BPlusTree.md)**: Planned tree-based indexing

---

## ğŸ¤ Contributing

This is an educational project. Contributions and improvements are welcome!

---

## ğŸ“„ License

Educational use - see repository for details.

---

**Built with â¤ï¸ for learning database internals**
